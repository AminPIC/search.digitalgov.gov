<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Posts tagged analytics</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="/bootstrap/css/bootstrap.css" rel="stylesheet">
  <link rel="stylesheet" href="/stylesheets/font-awesome.min.css">
  <!--[if IE 7]>
  <link rel="stylesheet" href="/stylesheets/font-awesome-ie7.min.css">
  <![endif]-->

  <!--<link href="../assets/css/bootstrap-responsive.css" rel="stylesheet">-->
  <link href="/stylesheets/custom.css" rel="stylesheet">

  <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
  <script src="/javascripts/html5shiv.js"></script>
  <![endif]-->

  <!-- Fav and touch icons -->
  <!--  <link rel="apple-touch-icon-precomposed" sizes="144x144"
          href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114"
          href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72"
          href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
  <link rel="shortcut icon" href="https://9fddeb862c037f6d2190-f1564c64756a8cfee25b6b19953b1d23.ssl.cf2.rackcdn.com/favicon.ico">
  <link rel='alternate' type='application/atom+xml' title='usasearch.howto.gov Atom feed' href='/all.atom' />
</head>

<body>
<div class="navbar navbar-inverse navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <a class="brand" href="/">
        <span class="digital">Digital</span><span class="gov">Gov</span>
        <span class="search">Search</span>
      </a>
      <ul class="nav">
        <li>
          <form class="form-search" accept-charset="UTF-8" action="http://search.usa.gov/search/news/" id="search-form" method="get">
            <input id="affiliate" name="affiliate" type="hidden" value="usasearch"/>
            <input type="hidden" name="channel" value="1745">
            <input type="hidden" name="sort_by" value="r">
            <input type="hidden" name="m" value="true">
            <div class="input-append">
              <label for="search-query" class="hide">Query</label>
              <input name="query" type="text" autocomplete="off"
                     class="usagov-search-autocomplete span search-query" id="search-query"/>
              <input type="submit" class="btn" id="search-button" value="Search" />
            </div>
          </form>
        </li>
      </ul>
      <ul class="nav login">
        <li>
          <a href="https://search.usa.gov/sites"><i
              class="icon-user icon-white"></i>&nbsp;Login</a>
        </li>
      </ul>
    </div>
  </div>
</div>


<div class="container">
  <div id="main-container"><!-- begin tag layout -->
<p class="muted">Posts tagged <strong>analytics</strong></p>
<div class='articles'>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/third-party.html">
        <time datetime="2014-03-05">March 5, 2014</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/third-party.html">How to Add JavaScript for Your Third Party Web Services</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Analytics > 3rd Party Tracking</p>

<p>Do you want your search results page to run web services such as 4Q, AddThis, Foresee, Google Analytics, Omniture, Siteimprove, or WebTrends?</p>

<p>Input the JavaScript code you'd like to call from your search results page. Click submit to send us your request. We'll input your code for you and send you an email to confirm that we've done it.</p>

<p>Some tips for commonly used third party web services follow.</p>

<h2>Google Analytics Tip</h2>

<p>In your Google Analytics JavaScript, be sure to set your domain if you've requested <a href="/manual/cname.html">domain masking</a> and you want to include your search subdomain (e.g., search.commerce.gov) with your main domain (e.g., commerce.gov).</p>

<pre><code>_gaq.push(['_setDomainName', 'commerce.gov']);
</code></pre>

<p>For more information, read Google's tip, <a href="https://developers.google.com/analytics/devguides/collection/gajs/gaTrackingSite">Tracking Multiple Domains</a>.</p>

<p>The code you submit should look something like one of the following two scripts.</p>

<h3>Google Analytics Code (Older Format)</h3>

<pre><code> &lt;script type="text/javascript"&gt;
 var _gaq = _gaq || []; 
 _gaq.push(['_setAccount', 'UA-########-1']); 
 _gaq.push(['_trackPageview']);

 (function() { 
 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; 
 ga.src = ('https:' == document.location.protocol ? 'https://ssl'; : 'http://www') +      '.google-analytics.com/ga.js'; 
 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); 
 })();

 &lt;/script&gt;
</code></pre>

<h3>Google Analytics Code (Newer Format)</h3>

<pre><code>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
</code></pre>

<h2>Digital Analytics Program Tip</h2>

<p>Does your federal agency participate in the <a href="http://www.digitalgov.gov/services/dap/">Digital Analytics Program</a> (DAP)?  You don't need to do anything. We're already fully integrated with DAP.</p>

<h2>ForeSee Tip</h2>

<p>Coordinate with your ForeSee representative and DigitalGov Search to implement your customer satisfaction survey on your results page. The four general steps follow.</p>

<ol>
<li><p>Email us at <a href="&#x6d;&#97;&#x69;&#x6c;&#x74;&#111;&#x3a;&#115;&#x65;&#97;&#x72;&#x63;&#104;&#64;&#x73;&#x75;&#112;&#112;&#x6f;&#x72;&#x74;&#46;&#100;&#x69;&#x67;&#x69;&#116;&#97;&#108;&#x67;&#111;&#x76;&#x2e;&#x67;&#x6f;&#118;">&#x73;&#101;&#97;&#114;&#x63;&#104;&#64;&#x73;&#117;&#x70;&#x70;&#111;&#x72;&#116;&#x2e;&#100;&#105;&#x67;&#x69;&#116;&#97;&#108;&#103;&#111;&#x76;&#46;&#103;&#111;&#118;</a> to <a href="/manual/cname.html">set up a CNAME</a> for search.youragency.gov.</p></li>
<li><p>Update the files path in your Foresee code to use an absolute path instead of a relative path.</p>

<p> <strong>Find =></strong> 'files': '/fsrscripts/',</p>

<p> <strong>and replace it with =></strong> 'files': '//www.youragency.gov/fsrscripts/',</p>

<p> <em>(Or, find => 'files': '/foresee/', and replace it with => 'files': '//www.youragency/foresee/',)</em></p>

<p> in the following five files.</p>

<ul>
<li>foresee-trigger.js</li>
<li>foresee-tracker.js</li>
<li>foresee-alive.js</li>
<li>foresee-qualifier.js</li>
<li>foresee-test.js</li>
</ul>
</li>
<li><p>Submit your foresee-trigger.js via our Admin Center. It should look something like the following.</p>

<pre><code>   &lt;script type="text/javascript" src="http://www.youragency.gov/library/foresee/foresee-trigger.js"&gt;&lt;/script&gt;
</code></pre></li>
<li><p>We'll send you an email to confirm that we've set up both your CNAME and added the script for your foresee-trigger.js file.</p></li>
</ol>


    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/third-party"><span class="label label-info">third-party</span></a>
      
      <a href="/tagged/google-analytics"><span class="label label-info">google-analytics</span></a>
      
      <a href="/tagged/foresee"><span class="label label-info">foresee</span></a>
      
      <a href="/tagged/DAP"><span class="label label-info">DAP</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/monthly-reports.html">
        <time datetime="2013-10-31">October 31, 2013</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/monthly-reports.html">How to Analyze Your Monthly Reports</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Analytics > Monthly Reports</p>

<p>The monthly report gives a bird's-eye view of the number of <a href="/manual/queries.html">queries</a> and <a href="/manual/clicks.html">clicks</a> each month.</p>

<p>Data are shown for the present month-to-date by default. You can change the time period by selecting a different month or year and re-generating the report.</p>

<p>Data start from the time your agency started using our service (but no further back than 2009).</p>

<h2>Monthly Usage Stats</h2>

<p>Data for the total number of queries and clicks. Use this report to find and analyze the so-called <a href="http://www.searchtools.com/analysis/long-tail.html">short head</a>&nbsp;<i class="icon-external-link"><span>(External link)</span></i> of your most popular search queries and clicks, which are typically the same as your site's <a href="http://www.howto.gov/web-content/manage/focus-on-top-tasks">top tasks</a>.</p>

<h2>Impressions and Clicks by Module</h2>

<p>Detailed data for the total number of impressions and clicks and your clickthru rate (CTR) are presented for each "module" on the search results page. We also provide the average CTR across all DigitalGov Search customers so you can see how your rate compares to the average rate. The data in the table is sorted in descending order from the most to least number of clicks.</p>

<p>Use this report to inform which <a href="/manual/display-overview.html">modules you opt to display</a>.</p>

<p><strong><em>Drill down into best bets.</em></strong> Select the option to drill down into your <a href="/manual/best-bets-text.html">Best Bets:Text</a> or <a href="/manual/best-bets-graphics.html">Best Bets: Graphics</a> to see the number of impressions, number of clicks, and CTR for each best bet. The data in the table is sorted in descending order from the highest to lowest CTR. Review and edit best bets as needed. Focus on those with a high number of impressions and low CTR to make the biggest impact on searchers' experience (and on your overall CTR). Select drill down again to see a pie chart of the search terms that led to an impression on each best bet.</p>

<h2>Download Top Queries</h2>

<p>View a detailed report of the number of times searchers have input specific terms and phrases by clicking on the CSV (comma-separated values) link to download the list as a text file. Once you've downloaded the CSV file, you can easily <a href="http://office.microsoft.com/en-us/excel-help/import-or-export-text-txt-or-csv-files-HP010342598.aspx">import it  into Excel</a>&nbsp;<i class="icon-external-link"><span>(External link)</span></i> or another speadsheet program to analyze the data.</p>

<p>The CSV file contains three columns: (1) query, (2) raw count, and (3) IP-deduped.</p>

<p>Read <a href="http://www.howto.gov/web-content/search/analyzing-search-terms">Understanding Your Users' Needs By Analyzing Search Terms</a> for tips on how to create a semi-automated report for analyzing the data in this CSV file on a regular basis.</p>

<h2>Definitions</h2>

<p>All data presented on this page (and other pages in the Admin Center) are IP-deduped to exclude bots and other noise in an attempt to accurately represent searchers' intent on your site. Some definitions follow.</p>

<p><strong><a href="/manual/queries.html">Queries</a>:</strong> Number of times a search query (that is, a word or string of words) was entered in the search box by a unique searcher.</p>

<p><strong><a href="/manual/clicks.html">Clicks</a>.</strong> Number of times a searcher clicked on one of your pages within the search results for a particular query.</p>

<p><strong>Impressions:</strong> Number of times a module is displayed, whether it is clicked on or not. Not all modules are displayed for all queries. Each time a module is displayed it is counted as one impression.</p>

<p><strong>Clickthru Rate (CTR):</strong> The rate (expressed in a percentage) at which searchers click on a module. This rate is calculated by dividing the total number of clicks by the total number of impressions. CTR is useful to measure the performance of specific campaigns, such as <a href="/manual/best-bets-text.html">best bets</a> for seasonal events.</p>

<p><strong>Raw count:</strong> Total number of times the query was submitted. The raw count is provided in the downloadable CSV files only.</p>

<p><strong>IP-deduped count:</strong> Total number of times the query was submitted by any one IP address. This excludes bots and other traffic that send in a query multiple times from one IP address. It is often a more accurate representation of "real," human traffic.</p>

<hr />

<p><strong><em>Did you know?</em></strong> On the first of each month, we email you a report with data on the previous month's queries, clicks, and top search terms.</p>

<p><strong><em>Did you know?</em></strong> The <a href="/manual/site-overview.html">Site Overview</a> provides a snapshot of what has been happening on your site in the past day or so.</p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/queries"><span class="label label-info">queries</span></a>
      
      <a href="/tagged/clicks"><span class="label label-info">clicks</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/queries.html">
        <time datetime="2013-09-20">September 20, 2013</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/queries.html">How to Analyze Your Queries</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Analytics > Queries</p>

<p>The Queries page reports on the number of times a search query (that is, a word or string of words) was entered in the search box on your site by a unique searcher.</p>

<p>Data are shown for the present month-to-date by default. You can change the time period by selecting a different month or year and re-generating the report.</p>

<p>Data start from the time your agency started using our service (but no further back than 2009).</p>

<h2>Top Queries</h2>

<p><strong><em>Top 1,000.</em></strong> You'll see a list, in frequency order, of top 1,000 most popular queries for your selected time period.</p>

<p><strong><em>Top 1,000 by query.</em></strong> Enter any specific term or phrase into the Query search box. Re-generate the report to see the top 1,000 queries that contain that term or phrase and its stemmed equivalents.</p>

<p>For example, below are the top 10 queries related to <em>housing</em> on USA.gov in August 2013.</p>

<ol>
<li>house of representatives</li>
<li>housing</li>
<li>speaker of the house</li>
<li>white house</li>
<li>house minority leader</li>
<li>housing assistance</li>
<li>house majority leader</li>
<li>speaker of the house 2013</li>
<li>the white house</li>
<li>houses</li>
</ol>


<h2>Query Clicks &amp; Click Queries</h2>

<p>Select the hyperlinked number in the # of Queries column to view the top clicked URLs for each query.</p>

<p>If you click on the first-listed <em>house of representatives</em> in the example above, you'll see that the top URLs clicked for that query are:</p>

<ol>
<li>www.house.gov</li>
<li>www.house.gov/representatives</li>
<li>www.house.gov/representatives/find</li>
</ol>


<p>From this list of clicked URLs, you'll be able select the hyperlinked number in the # of Clicks column to view the top queries that led to a click for each URL.</p>

<p>If you click on the first-listed <em>www.house.gov</em> in the example above, you'll see that the top queries leading to a click on that URL are:</p>

<ol>
<li>house of representatives</li>
<li>congress</li>
<li>congress members</li>
<li>congress representatives</li>
</ol>


<p>You can loop through or drill down into this list for any set of clicks and queries.</p>

<hr />

<p><strong><em>Did you know?</em></strong> The <a href="/manual/monthly-reports.html">Monthly Report</a> gives a bird's-eye view of the number of queries and <a href="/manual/clicks.html">clicks</a> each month. The <a href="/manual/site-overview.html">Site Overview</a> provides a snapshot of what has been happening on your site in the past day or so.</p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/queries"><span class="label label-info">queries</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/clicks.html">
        <time datetime="2013-09-20">September 20, 2013</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/clicks.html">How to Analyze Your Clicks</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Analytics > Clicks</p>

<p>The Clicks page reports on the number of times a unique searcher clicked on one of your pages within the search results for a particular query.</p>

<p>Data are shown for the present month-to-date by default. You can change the time period by selecting a different month or year and re-generating the report.</p>

<p>Data start from the time your agency started using our service (but no further back than 2009).</p>

<h2>Top Clicks</h2>

<p><strong><em>Top 1,000.</em></strong> You'll see a list, in frequency order, of top 1,000 most popular clicks for your selected time period.</p>

<p>For example, below are the top 10 clicked URLs for USA.gov in August 2013.</p>

<ol>
<li>www.usajobs.gov</li>
<li>travel.state.gov/visa/immigrants/types/types_1322.html</li>
<li>www.usa.gov/shopping/shopping.shtml</li>
<li>www.usa.gov/Citizen/Topics/Government-Unclaimed-Money.shtml</li>
<li>www.annualcreditreport.com/</li>
<li>www.travel.state.gov/passport/passport_1738.html</li>
<li>www.ssa.gov</li>
<li>travel.state.gov/visa/immigrants/types/types_1318.html</li>
<li>www.usajobs.gov/</li>
<li>travel.state.gov/passport/renew/renew_833.html</li>
</ol>


<h2>Click Queries &amp; Query Clicks</h2>

<p>Select the hyperlinked number in the # of Clicks column to view the top queries that led to a click for each URL.</p>

<p>If you click on the first-listed <em>www.usajobs.gov</em> in the example above, you'll see that the top queries leading to a click on that URL are:</p>

<ol>
<li>jobs</li>
<li>jobs openings</li>
<li>usa jobs</li>
<li>employment</li>
<li>job search</li>
</ol>


<p>From this list of top queries leading to a click, you'll be able select the hyperlinked number in the # of Clicks column to view the top clicks for each query.</p>

<p>If you click on the fourth-listed <em>employment</em> in the example above, you'll see that the the top URLs clicked for that query are:</p>

<ol>
<li>www.usajobs.gov</li>
<li>www.usajobs.gov/JobSearch/Search/GetResults</li>
<li>www.bls.gov/ces</li>
<li>www.cdc.gov/employment</li>
</ol>


<p>You can loop through or drill down into this list for any set of clicks and queries.</p>

<hr />

<p><strong><em>Did you know?</em></strong> The <a href="/manual/monthly-reports.html">Monthly Report</a> gives a bird's-eye view of the number of <a href="/manual/queries.html">queries</a> and clicks each month. The <a href="/manual/site-overview.html">Site Overview</a> provides a snapshot of what has been happening on your site in the past day or so.</p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/clicks"><span class="label label-info">clicks</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/raw-logs.html">
        <time datetime="2013-08-28">August 28, 2013</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/raw-logs.html">How to Access Your Raw Logs</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Analytics > Raw Logs Access</p>

<p>You can directly access your raw HTTP logs. The logs include valuable data on searches, clicks, and discovery tag page loads.</p>

<p>With the raw logs, you can conduct in-depth, ad hoc analyses to answer any questions that you can't answer using the standard analytics reports in the <a href="https://search.usa.gov/sites/">Admin Center</a>. You can also automatically integrate your search logs with your other reports and business processes.</p>

<p>To access your raw logs, you'll first need to upload your public key on the Raw Logs Access page in the <a href="https://search.usa.gov/sites/">Admin Center</a>.</p>

<p>We'll set up your public key on our secure FTP servers and send you an email when your logs are available for download.</p>

<p>Once your key is set up, you'll be able access your log files via secure FTP. We upload your logs each day, usually within several hours after midnight GMT. After a week, we purge the older files.</p>

<p>We recommend that you set up a cron script to automatically download the latest files each day.</p>

<h2>How to Generate a Key Pair on Unix</h2>

<p>On Unix systems, you can generate a RSA public key with no passphrase by typing in the following command. Generate the key from the machine or server that you'll be using to download the logs. Once you've created a key, it'll be located at /home/user/.ssh/id_rsa.pub.</p>

<pre><code>% cd ~
% ssh-keygen -q -b 4096 -t rsa
Enter file in which to save the key (/home/user/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
</code></pre>

<h2>How to Generate a Key Pair on Windows</h2>

<p>You can use <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/">PuTTY</a>, a free telnet/SSH client, to generate a public key on Windows. Download PuTTYgen.exe, Pageant.exe, and PSFTP.exe from the <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">PuTTY Download Page</a>.</p>

<p>Run PuTTYgen.exe.</p>

<ul>
<li>Select SSH-2 RSA as the type of key to generate.</li>
<li>Set the number of bits in the generated key to 2048.</li>
<li>Select Generate. Move your mouse within the blank area to create random movements until the key is generated.</li>
<li>Fill out your Key Comment, Key Passphrase, and Confirm Passphrase.</li>
<li>Copy your <em>public</em> key from the string in the Public Key for Pasting into OpenSSH Authorized_keys File. Paste this key into the Raw Logs Access page in the <a href="https://search.usa.gov/sites/">Admin Center</a>. (Note: Don't save this public key and send us the string copied from a text file. It adds lines in the file so it doesn't work.)</li>
<li>Save your <em>private</em> key.</li>
</ul>


<p>Run Pageant.exe. Select Add Key and upload your private key, the .ppk file.</p>

<p>Run PSFTP.exe and type in the following. You can find your site's handle on the Site Information page in the <a href="https://search.usa.gov/sites/">Admin Center</a>.</p>

<pre><code>open YourSiteHandle@198.61.238.46
</code></pre>

    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/raw-logs"><span class="label label-info">raw-logs</span></a>
      
      <a href="/tagged/sftp"><span class="label label-info">sftp</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <span>Last updated on:</span>
      
      <a href="/manual/site-overview.html">
        <time datetime="2013-08-20">August 20, 2013</time>
      </a>
    </div>

    
    <h1>
      <a href="/manual/site-overview.html">How to View a Snapshot of What's Happening on Your Site Today</a>
    </h1>
    

    <div class='post-content'>
      <p><a href="/index.html">DigitalGov Search</a> > <a href="https://search.usa.gov/sites/">Admin Center</a> > YourSite > Dashboard > Site Overview</p>

<p>The Site Overview page provides a snapshot of what has been happening on your site in the past day or so.</p>

<p>You can also opt to receive this snapshot as a daily email by clicking on the envelope icon next to your selected site.</p>

<h2>Top Queries</h2>

<p>Reports on the top 10 searches done by searchers on your site. If you don't have any searches, you'll see a message that there aren't enough query data available. These typically don't require any action as they don't change much from day-to-day.</p>

<p>Note that the data are processed to present "real" searches by humans (that is, the data are de-duped by IP address to remove bot traffic and other noise).</p>

<h2>Top Clicked URLs</h2>

<p>Reports on the top 10 pages that were clicked thru by searchers on your search results page. If you don't have any clicks, you'll see a message that there aren't enough click data available. These typically don't require any action as they don't change much from day-to-day.</p>

<h2>Trending URLs</h2>

<p>If there are any pages that are trending, they'll appear here. Reports on up to the top 10 changing URLs that were <em>visited by users on your website</em>.</p>

<p>Use this report to identify newly popular pages on your website. Investigate why pages are trending, if the reason is not immediately apparent.</p>

<p>Note that you'll only see this list of trending URLs if you have our <a href="/manual/code.html">Javascript snippet</a> on your web pages. Data are updated every few minutes so this is near real-time information and you may see URLs come and go quickly.</p>

<h2>Trending Queries</h2>

<p>If there are any queries that are trending, they'll appear here. Reports on up to the top 10 changing search terms with the greatest <em>gain</em> between yesterday and today.</p>

<p>Use this report to identify newly popular terms. Create new content or update existing content to ensure it's current, accurate, and complete.</p>

<h2>Queries with No Results</h2>

<p>If there are any terms that returned no results, they'll appear here. Reports on up to the top 10 queries with no results.</p>

<p>For example, on one agency's website in October 2012, a dozen searches for <em>frostline</em> returned no results. The frost line&mdash;also known as depth of frost or freezing&mdash;is the depth to which the groundwater in soil is expected to freeze. The agency's pages on the topic referred to this concept as <em>depth of freezing</em>.</p>

<p>Use this alert about results data to help searchers find your content by adding a <a href="/manual/best-bets-text.html">Best Bet</a>, updating your existing web pages, or both.</p>

<h2>Top Queries with Low Click Thrus</h2>

<p>If there are any frequently searched terms that returned results but didn't result in a click at least 20% of the time, they'll appear here. Reports on up to the top 10 searches with low click thru rates.</p>

<p>Use this alert about low click thrus to identify issues with coverage. You may opt to create a <a href="/manual/best-bets-text.html">Best Bet: Text</a> or <a href="/manual/best-bets-graphics.html">Best Bet: Graphics</a>, add pages that may be missing from the results, or do both to improve recall. Or, you may opt to incorporate language from these popular search terms into your titles and descriptions to improve the relevance of results.</p>

<h2>This Month's Totals to Date</h2>

<p>Reports on the total number of queries and clicks for the present month-to-date. A click  is recorded each time a searcher clicks on a results link.</p>

<p>A graph of your site's total search queries over time is also presented to provide an overview of how your traffic has trended from the time your agency started using our service (but no further back than 2010). Hover over the trend line to see the total number of queries in previous months.</p>

<hr />

<p><strong><em>Did you know?</em></strong> The <a href="/manual/monthly-reports.html">Monthly Report</a> gives a bird's-eye view of the number of <a href="/manual/queries.html">queries</a> and <a href="/manual/clicks.html">clicks</a> each month.</p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/how-to"><span class="label label-info">how-to</span></a>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/dashboard"><span class="label label-info">dashboard</span></a>
      
      <a href="/tagged/site-overview"><span class="label label-info">site-overview</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <a href="/blog/award-big-data.html">
        <time datetime="2011-11-14">November 14, 2011</time>
      </a>
    </div>

    
    <h1>
      <a href="/blog/award-big-data.html">DigitalGov Search Wins Government Big Data Solutions Award</a>
    </h1>
    

    <div class='post-content'>
      <p>DigitalGov Search (formerly USASearch) is the <a href="http://ctolabs.com/gsa-usasearch-wins-2011-government-big-data-solutions-award">winner of the 2011 Government Big Data Solutions Award</a>, announced at <a href="http://www.hadoopworld.com">Hadoop World</a> in New York City on November 8, 2011.</p>

<p>The <a href="http://ctolabs.com/big-data-award">Big Data Award</a> was established to highlight innovative solutions and to facilitate the exchange of best practices, lessons learned, and creative ideas for addressing Big Data challenges. The Award judges saw DigitalGov Search as a great example of solving Big Data problems to improve government agility and to provide better service for less.</p>

<p>In line with the GSA's cost-saving "build once, use many times" paradigm, DigitalGov Search provides hosted search services for <a href="http://www.usa.gov">USA.gov</a> and hundreds of other government websites. This is done in a cost-effective way, especially for the agencies involved, which receive these services at no cost.</p>

<p>From the Award presentation:</p>

<blockquote><p>The GSA is to be congratulated for their mission-focused, citizen-centered, open approach to a big data challenge and a resulting solution that improves the experience of a broad swath of users of federal services. On behalf of our judges and the many citizens who use this capability on a daily basis we say thank you, and congratulations on this well deserved recognition.</p></blockquote>

    </div>

    <div class='tags'>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/about-us"><span class="label label-info">about-us</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <a href="/blog/hadoop-rubyists.html">
        <time datetime="2011-11-09">November 9, 2011</time>
      </a>
    </div>

    
    <h1>
      <a href="/blog/hadoop-rubyists.html">Hadoop for Rubyists</a>
    </h1>
    

    <div class='post-content'>
      <p>Is your MySQL groaning under too much data? Tired of waiting hours for analytics rake tasks?</p>

<p><a href="http://pivotallabs.com/talks/150-hadoop-for-rubyists"><img src="https://9fddeb862c037f6d2190-f1564c64756a8cfee25b6b19953b1d23.ssl.cf2.rackcdn.com/tumblr_luckbhCakH1qid15q.png" alt="Hadoop for Rubyists video" /></a></p>

<p><a href="http://pivotallabs.com/talks/150-hadoop-for-rubyists">Listen to Loren</a>, DigitalGov Search's senior technical architect, as he discusses how we leveraged our existing Ruby codebase by building Hadoop Map/Reduce jobs using Hive and plugging in our own Ruby mappers/reducers.</p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/about-us"><span class="label label-info">about-us</span></a>
      
    </div>
  </article>
  
  <article class='article'>
    <div class='time'>
      
      <a href="/blog/adopting-hadoop.html">
        <time datetime="2011-06-16">June 16, 2011</time>
      </a>
    </div>

    
    <h1>
      <a href="/blog/adopting-hadoop.html">Adopting Apache Hadoop in the Federal Government</a>
    </h1>
    

    <div class='post-content'>
      <h2>Background</h2>

<p>The United States federal government's DigitalGov Search program provides hosted search services for government affiliate organizations, shares APIs and web services, and operates the government's official search engine on <a href="http://www.usa.gov">USA.gov</a>. DigitalGov Search offers free search services to any federal, state, local, tribal, or territorial government agency. Several hundred websites make use of this service, ranging from the smallest municipality to larger federal sites like <a href="http://www.weather.gov">http://www.weather.gov</a> and <a href="http://www.usa.gov">http://www.usa.gov</a>. DigitalGov Search leverages the Bing API as the basis for its web results and then augments the user search experience by providing a variety of government-centric information such as related search topics and highlighted editorial content. The entire system is comprised of a suite of open-source tools and resources, including Apache Solr/Lucene, OpenCalais, and Apache Hadoop. Of these, our usage of Hadoop is the most recent. We began using <a href="http://www.cloudera.com/hadoop/">Cloudera's Distribution including Apache Hadoop</a>&nbsp;<i class="icon-external-link"><span>(External link)</span></i> (CDH3) for the first time in the Fall, and since then we've seen our usage grow every month&mdash;not just in scale, but in scope as well. But before highlighting everything DigitalGov Search is doing with Hadoop today, I should explain why we began using it in the first place.</p>

<h2>Phase 1: Search analytics</h2>

<p>All of the search and <a href="/manual/api.html">API</a> traffic across hundreds of affiliate sites, iPhone apps, and widgets comes through a single search service, and this generates a lot of data. To improve the service, administrators wanted to see aggregated information on what sorts of information searchers were looking for, how well they were finding it, what trends were forming, and so on. Once searches were initiated, they also wanted to know what results were shown and then what results were clicked on. They wanted to see all this information broken down by affiliate over time, and also aggregated across the entire affiliate landscape.</p>

<p>The initial system, like many initial systems, was fairly simple and did just enough to address our most pressing analytics needs. We took the logs from Apache and Ruby on Rails, put them in a big MySQL database on a separate machine, ran nightly and monthly jobs on them, and then exported the summary results to the main database cluster to be served up via a low-latency Rails web interface for analytics. We used a separate physical database machine with lots of memory and disk for the batch processing to keep our production MySQL instances from being impacted by this resource-intensive batch processing.</p>

<p><img src="https://9fddeb862c037f6d2190-f1564c64756a8cfee25b6b19953b1d23.ssl.cf2.rackcdn.com/tumblr_lle73iJ2Ts1qid15q.png" alt="Initial dataflow of raw logfiles to analytics apps" /></p>

<p>As we watched the main database tables grow and the nightly batch jobs take longer and longer, it became clear that we would soon exhaust the resources available on the single database analytics processing node. We looked at scaling up the hardware vertically and sharding the database horizontally, but both options seemed like we were just kicking the can down the road. Larger database hardware would be both costly and eventually insufficient for our needs, and sharding promised to take all the usual issues associated with a single database system (backups, master/slaves, schema management) and multiply them. We wanted the system to be able to grow cost effectively and without downtime, be naturally resilient to failures, and have backups handled sensibly. It was at this point that we started investigating HDFS, Hadoop, and Apache Hive.</p>

<p>HDFS offered us a distributed, resilient, and scalable filesystem while Hadoop promised to bring the work to where the data resided so we could make efficient use of local disk on multiple nodes. Hive, however, really pushed our decision in favor of a Hadoop-based system. Our data is just unstructured enough to make traditional RDBMS schemas a bit brittle and restrictive, but has enough structure to make a schema-less NoSQL system unnecessarily vague. Hive let us compromise between the two&mdash;it's sort of a "SomeSQL" system.</p>

<p>But best of all, we could layer the entire Cloudera stack on top of a subset of our existing production machines. By making use of each machine's excess reserve capacity of disk, CPU, and RAM, we were able to get a small proof-of-concept cluster stood up without purchasing any new hardware. The initial results confirmed that our workload lent itself well to distributed processing, as one job went from taking over an hour on a MySQL node to 20 minutes on a three machine Hadoop cluster. Within a week of getting the prototype up and running, we had transitioned all the remaining nightly analytics batch SQL jobs into Hive scripts. The job output fed into a collection of intermediate Hive tables, from which we generated summary data to export to MySQL as low-latency tables for the Rails web interface to use. To prove the scaling point, we spent five minutes adding another datanode/tasktracker to the mix, kicked off the cluster rebalancer, and the whole process ran faster the next day.</p>

<p><img src="https://9fddeb862c037f6d2190-f1564c64756a8cfee25b6b19953b1d23.ssl.cf2.rackcdn.com/tumblr_lle73rea1K1qid15q.png" alt="Current dataflow of raw logfiles to analytics apps" /></p>

<h2>Phase 2: Feedback loop</h2>

<p>The result of all this analysis in Hive shows up not just in various analytics dashboards, but as part of the search experience on many government websites, too. For example, compare the different type-ahead suggestions for '<strong>gran</strong>' on <a href="http://www.nps.gov">http://www.nps.gov</a> and <a href="http://www.usa.gov">http://www.usa.gov</a>. Both sites use the same DigitalGov Search backend system, but the suggestions differ completely. We use Hadoop to help us generate contextually relevant and timely search suggestions for hundreds of government sites like this.</p>

<p><img src="https://9fddeb862c037f6d2190-f1564c64756a8cfee25b6b19953b1d23.ssl.cf2.rackcdn.com/tumblr_lle73ymed31qid15q.png" alt="Different type-ahead suggestions on NPS.gov and USA.gov" /></p>

<h2>Phase 3: Internal monitoring</strong></h2>

<p>Shortly after moving our event stream analysis from MySQL to Hadoop/Hive, we noticed a change in how we thought about data. Freed from the constant anxiety of wondering how we were going to handle an ever-increasing amount of data, we shifted from trying to store only what we really needed to storing whatever we thought might be useful. We first turned our attention to the performance data emitted by the various sub-systems that make up the search program.</p>

<p>Each search results page is potentially made up of many data modules sintered together from calls to the Bing API, our own Solr indexes, a MySQL cluster, and a Redis cache. A small latency problem with any one of them can propagate through the system to create much larger problems, so we want to have a deep knowledge of how each subsystem behaves throughout the day under various circumstances. We were already monitoring the availability of all these services with Opsview, but we had no insight into their performance over time. Whenever we sensed a problem ("Is one of the Solr indexes getting slow?"), we would liberally apply ssh, tail -f, and grep to try to see what was going on. This seemed like a good use case for Hive, so in the case of Solr, for example, we threw the compressed log files into HDFS, wrote a simple SerDe regular expression to define rows in a Hive table partitioned by date, and built a view on top of that for easy manipulation of extracted columns such as the Solr index name and the hour of day. Hive makes it trivially easy to do some fairly sophisticated aggregate analysis on the response times for each Solr index, such as generating a distribution histogram, or calculating the pth percentile.</p>

<p>Some of these Hive queries are not run very often&mdash;perhaps just a few times a month&mdash;so we don't want to spend time building them into our test-driven Rails analytics framework. On the other hand, they are complex enough that we don't want to rewrite them every time we want to use them. For these cases, we use Beeswax in HUE to save off parameterized queries that can then be shared among engineers or analysts to run on an ad hoc basis.</p>

<h2>Conclusion</h2>

<p>In the space of a few months, we've gone from having a brittle and hard-to-scale RDBMS-based analytics platform to a much more agile Hadoop-based system that was designed to scale intrinsically. We continue to see our Hadoop usage grow in scope with each new data source we add, and it's clear that we'll be relying on it more and more in the future as the suite of tools and resources around Hadoop grows and matures.</p>

<p><strong><em>This post is cross-posted from <a href="http://www.cloudera.com/blog/2011/04/adopting-apache-hadoop-in-the-federal-government">Cloudera</a>&nbsp;<i class="icon-external-link"><span>(External link)</span></i>.</em></strong></p>

    </div>

    <div class='tags'>
      
      <a href="/tagged/analytics"><span class="label label-info">analytics</span></a>
      
      <a href="/tagged/about-us"><span class="label label-info">about-us</span></a>
      
    </div>
  </article>
  
</div>


<ul class="pager">
  

  
</ul>
<!-- end tag layout --></div>
</div>

<footer class="footer">
  <div class="container">
    <p><a href="mailto:search@support.digitalgov.gov">Email us</a>, call us at 202-505-5315, or follow <a href="http://www.twitter.com/dg_search">@DG_Search</a></p>
    <p> An Official Website of the U.S. Government <br />
      <a href="http://www.gsa.gov/portal/category/25729">Office of Citizen Services &amp; Innovative Technologies</a>, <a href="http://www.gsa.gov">U.S. General Services Administration</a>
    </p>
    <ul class="footer-links unstyled inline">
      <li><a href="http://www.usa.gov">USA.gov</a></li>
      <li class="muted">&bull;</li>
      <li><a href="/tos.html">Terms of Service</a></li>
      <li class="muted">&bull;</li>
      <li><a href="http://www.digitalgov.gov/about/policies/">Site Policies</a></li>
    </ul>
  </div>
</footer>

<script type="text/javascript">
  //<![CDATA[
  var usasearch_config = { siteHandle:"usasearch" };

  var script = document.createElement("script");
  script.type = "text/javascript";
  script.src = "http://search.usa.gov/javascripts/remote.loader.js";
  document.getElementsByTagName("head")[0].appendChild(script);

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31302465-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  //]]>
</script>


</body>
</html>
