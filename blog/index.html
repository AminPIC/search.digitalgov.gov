<!DOCTYPE html>
<html lang="en">
<head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  
  <title>Search.gov Blog</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" media="screen" rel="stylesheet" type="text/css" />
  <link href="/bootstrap/css/bootstrap.css" rel="stylesheet">
  <link rel="stylesheet" href="/stylesheets/font-awesome.min.css">
  <!--[if IE 7]>
  <link rel="stylesheet" href="/stylesheets/font-awesome-ie7.min.css">
  <![endif]-->

  <!--<link href="../assets/css/bootstrap-responsive.css" rel="stylesheet">-->
  <link href="/stylesheets/custom.css" rel="stylesheet">

  <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
  <script src="/javascripts/html5shiv.js"></script>
  <![endif]-->

  <!-- Fav and touch icons -->
  <!--  <link rel="apple-touch-icon-precomposed" sizes="144x144"
          href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114"
          href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72"
          href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
  <link rel="shortcut icon" href="https://d3qcdigd1fhos0.cloudfront.net/blog/img/favicon.ico">
  <link rel='alternate' type='application/atom+xml' title='search.gov Atom feed' href='/all.atom' />
  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
  <script src="/javascripts/bootstrap3-typeahead.js"></script>
</head>

<body>
<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <a class="navbar-brand" href="/">
        <span class="search">Search.gov</span>
      </a>
    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">

      <form class="navbar-form navbar-left form-search" accept-charset="UTF-8" action="https://find.search.gov/search/" id="search-form" method="get">
        <div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
        <input name="affiliate" id="affiliate" type="hidden" value="usasearch">
        <div class="input-group input-append">
          <label for="search-query" class="hide">Query</label>

          <input name="query" autocomplete="off"  type="text" class="typeahead form-control search-query" id="search-query" data-provide="typeahead" >
          <span class="input-group-btn">
            <button type="submit" class="btn btn-nav" aria-label="Left Align" id="search-button">
              <span class="glyphicon glyphicon-search" aria-hidden="true"></span>
            </button>
          </span>
        </div>
      </form>
      <div class="nav navbar-right">
          <a href="https://search.usa.gov/sites" class="navbar-brand"><i
              class="icon-user icon-white"></i>&nbsp;Login</a>
      </div>&nbsp;&nbsp;&nbsp;<div class="nav navbar-right">
          <a href="http://search.usa.gov/signup" class="navbar-brand">Sign up</a>
      </div>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>


<div class="col-md-offset-2 col-md-8  hidden-sm hidden-md hidden-lg">

  <form class="form-search" accept-charset="UTF-8" action="https://find.search.gov/search/" id="search-form" method="get">
    <input name="affiliate" id="affiliate" type="hidden" value="usasearch">
    <div class="input-group input-append">
      <label for="search-query" class="hide">Query</label>

      <input name="query" autocomplete="off"  type="text" class=" form-control search-query" id="search-query"  >
      <span class="input-group-btn">
        <button type="submit" class="btn btn-primary" aria-label="Left Align" id="search-button">
          <span class="glyphicon glyphicon-search" aria-hidden="true"></span>
        </button>
      </span>
    </div>
  </form>
</div>


<div class="container-fluid">
  <div class="col-md-8 col-md-offset-2">
    <!-- do not remove as used to parse in usasearch -->
    <main id="main-container">
      <!-- begin /blog/index.md content -->
<div class="articles">

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/releases/september-2018.html"&gt;September 2018 Release Notes&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;h2 id="highlights"&gt;Highlights&lt;/h2&gt;
</code></pre>
    <ul>
  <li>We began work on using click data in our relevancy ranking, starting with
    <ul>
      <li>Recording the domain of the clicked-on URL separately, so we can manage all the clicks for a particular domain.</li>
      <li>Calculating the top N clicked-on URLs for a given domain.</li>
    </ul>
  </li>
</ul>

    <h2 id="chores">Chores</h2>
    <ul>
  <li>We indexed a lot of content for agencies.</li>
  <li>We got our new developers set up and ready to work on great stuff.</li>
</ul>

    <h2 id="bug-fixes">Bug Fixes</h2>
    <ul>
  <li>None</li>
</ul>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/release-notes"&gt;&lt;span class="label label-info"&gt;release-notes&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  &lt;/br&gt;&lt;span&gt;Page last reviewed or updated:&lt;/span&gt;
  
  
  
  &lt;a href="/releases/september-2018.html"&gt;
    &lt;time datetime="2018-11-02"&gt;November 2, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/blog/robotstxt.html"&gt;Robots.txt Files&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;A &lt;code&gt;/robots.txt&lt;/code&gt; file is a text file that instructs automated web bots on how to crawl and/or index a website. Web teams use them to provide information about what site directories should or should not be crawled, how quickly content should be accessed, and which bots are welcome on the site.&lt;/p&gt;
</code></pre>

    <h2 id="what-should-my-robotstxt-file-look-like">What should my robots.txt file look like?</h2>
    <p>Please refer to the <a href="http://www.robotstxt.org/robotstxt.html">robots.txt protocol</a>  <i class="icon-external-link"><span>(External link)</span></i> for detailed information on how and where to create your robots.txt. Key points to keep in mind:</p>

    <ul>
  <li>The file must be located at the root of the domain, and each subdomain needs its own file.</li>
  <li>The robots.txt protocol is case sensitive.</li>
  <li>It’s easy to accidentally block crawling of everything
    <ul>
      <li><code>Disallow: /</code> means disallow everything</li>
      <li><code>Disallow:  </code> means disallow nothing, thus allowing everything</li>
      <li><code>Allow: /</code> means allow everything</li>
      <li><code>Allow:  </code> means allow nothing, thus disallowing everything</li>
    </ul>
  </li>
  <li>The instructions in robots.txt are guidance for bots, not binding requirements.</li>
</ul>

    <h2 id="how-can-i-optimize-my-robotstxt-for-searchgov">How can I optimize my robots.txt for Search.gov?</h2>

    <h3 id="crawl-delay">Crawl delay</h3>
    <p>A robots.txt file may specify a “crawl delay” directive for one or more user agents, which tells a bot how quickly it can request pages from a website. For example, a crawl delay of 10 specifies that a crawler should not request a new page more than every 10 seconds.  We recommend a crawl-delay of 2 seconds for our <code>usasearch</code> user agent, and setting a higher crawl delay for all other bots. The lower the crawl delay, the faster Search.gov will be able to index your site. In the robots.txt file, it would look like this:</p>

    <pre><code>User-agent: usasearch  
Crawl-delay: 2

User-agent: *
Crawl-delay: 10
</code></pre>

    <h3 id="xml-sitemaps">XML Sitemaps</h3>
    <p>Your robots.txt file should also list one or more of your <a href="https://search.gov/blog/sitemaps.html">XML sitemaps</a>. For example:</p>

    <pre><code>Sitemap: https://www.exampleagency.gov/sitemap.xml
Sitemap: https://www.exampleagency.gov/independent-subsection-sitemap.xml
</code></pre>
    <ul>
  <li>Only list sitemaps for the domain matching where the robots.txt file is. A different subdomain’s sitemap should be listed on that subdomain’s robots.txt.</li>
</ul>

    <h3 id="allow-only-the-content-that-you-want-searchable">Allow only the content that you want searchable</h3>
    <p>We recommend disallowing any directories or files that should not be searchable. For example:</p>

    <pre><code>Disallow: /archive/
Disallow: /news-1997/
Disallow: /reports/duplicative-page.html
</code></pre>

    <ul>
  <li>Note that if you disallow a directory after it’s been indexed by a search engine, this may not trigger a removal of that content from the index. You’ll need to go into the search engine’s webmaster tools to request removal.</li>
  <li>Also note that search engines may index individual pages within a disallowed folder if the search engine learns about the URL from a non-crawl method, like a link from another site or your sitemap. To ensure a given page is not searchable, set a <a href="/blog/how-search-engines-index-content-better-discoverability.html#robots">robots meta tag</a> on that page.</li>
</ul>

    <h3 id="customize-settings-for-different-bots">Customize settings for different bots</h3>
    <p>You can set different permissions for different bots. For example, if you want us to index your archived content but don’t want Google or Bing to index it, you can specify that:</p>

    <pre><code>User-agent: usasearch  
Crawl-delay: 2
Allow: /archive/

User-agent: *
Crawl-delay: 10
Disallow: /archive/
</code></pre>

    <h2 id="robotstxt-checklist">Robots.txt checklist</h2>
    <p><i class="icon-check"></i> 1. A robots.txt file has been created in the site’s root directory (<code>https://exampleagency.gov/robots.txt</code>)</p>

    <p><i class="icon-check"></i> 2. The robots.txt file disallows any directories and files that automated bots should not crawl</p>

    <p><i class="icon-check"></i> 3. The robots.txt file lists one or more <a href="https://search.gov/blog/sitemaps.html">XML sitemaps</a></p>

    <p><i class="icon-check"></i> 4. The robots.txt file format has been <a href="http://tools.seochat.com/tools/robots-txt-validator/">validated</a>  <i class="icon-external-link"><span>(External link)</span></i></p>

    <h2 id="additional-resources">Additional Resources</h2>
    <p><a href="https://yoast.com/ultimate-guide-robots-txt/">Yoast SEO’s Ultimate Guide to Robots.txt</a>  <i class="icon-external-link"><span>(External link)</span></i></p>

    <p><a href="https://support.google.com/webmasters/answer/6062608?hl=en&amp;ref_topic=6061961">Google’s “Learn about robots.txt files”</a>  <i class="icon-external-link"><span>(External link)</span></i></p>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/how-to"&gt;&lt;span class="label label-info"&gt;how-to&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/manage-content"&gt;&lt;span class="label label-info"&gt;manage-content&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/indexing"&gt;&lt;span class="label label-info"&gt;indexing&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  &lt;/br&gt;&lt;span&gt;Page last reviewed or updated:&lt;/span&gt;
  
  
  
  
  &lt;a href="/blog/robotstxt.html"&gt;
    &lt;time datetime="2018-10-11"&gt;October 11, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/blog/how-search-engines-index-content-better-discoverability.html"&gt;How to get search engines to index the right content for better discoverability&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;Website structure and content can have a significant impact on the ability of search engines to provide a good search experience. As a result, the Search Engine Optimization industry evolved to provide better understanding of these impacts and close critical gaps. Some elements on your website will actively hinder the search experience, and this post will show you how to target valuable content and exclude distractions.&lt;/p&gt;
</code></pre>

    <p>We’ve written a <a href="/blog/robotstxt.html">post about robots.txt files</a>, talking about high level inclusion and exclusion of content from search engines. There are other key tools you will want to employ on your website to further target the content on individual pages:</p>

    <ul>
  <li><a href="#main-element">The &lt;main&gt; element</a></li>
  <li><a href="#rel-canonical">Canonical links</a></li>
  <li><a href="#robots">Robots meta tags</a></li>
  <li>Or a combination of the above: <a href="#sample">Sample code structure for dynamic lists and an archived event</a></li>
</ul>

    <p><br />
<a id="main-element"></a></p>
    <h2 id="the-main-element">The <code>&lt;main&gt;</code> element</h2>
    <h3 id="targeting-particular-content-on-a-page">Targeting particular content on a page</h3>

    <p>A <code>&lt;main&gt;</code> element allows you to target content you want indexed by search engines. If a <code>&lt;main&gt;</code> element is present, the system will only collect the content inside the element. Be sure that the content you want indexed is inside of this element. If the element is closed too early, important content will not be indexed. Unless the system finds a <code>&lt;main&gt;</code> element demarcating where the primary content of the page is to be found, repetitive content such as headers, footers, and sidebars will be picked up by search engines as part of a page’s content.</p>

    <p>The element is implemented as a stand-alone tag:</p>

    <pre><code>&lt;body&gt;
Redundant header code and navigation elements, sidebars, etc.
&lt;main&gt;
&lt;h1&gt;This is your page title&lt;/h1&gt;
&lt;p&gt;This is the main text of your page
&lt;/main&gt;
Redundant footer code
Various scripts, etc.
&lt;/body&gt;
</code></pre>

    <p>The element can also take the form of a <code>&lt;div&gt;</code> with the role of main, though this approach is now outdated:</p>

    <pre><code>&lt;body&gt;
Redundant header code and navigation elements, sidebars, etc.
&lt;div role=”main”&gt;
&lt;h1&gt;This is your page title&lt;/h1&gt;
&lt;p&gt;This is the main text of your page
&lt;/div&gt;
Redundant footer code
Various scripts, etc.
&lt;/body&gt;
</code></pre>

    <p>As mentioned above, if no <code>&lt;main&gt;</code> element is present, the entire page will be scraped. This is best reserved for non-HTML file types, though, including PDFs, DOCs, and PPTs.</p>

    <p><br />
<a id="rel-canonical"></a></p>
    <h2 id="canonical-links">Canonical links</h2>
    <h3 id="declare-the-real-url-for-a-page">Declare the ‘real’ URL for a page</h3>

    <p>There are two good reasons to declare the URL for a given page: CMS sites can easily become crawler traps, and list views can generate urls that are unhelpful as search results.</p>

    <p>A crawler trap occurs when the engine falls into a loop of visiting, opening, and “discovering” pages that seem new, but are modifications on existing URLs. These URLs may have appended parameters such as tags, referring pages, Google Tag Manager tokens, page numbers, etc. Crawler traps tend to occur when your site can generate an infinite number of URLs. The crawler is ultimately unable to determine what constitutes the entirety of a site.
<code>&lt;link rel="canonical" href="https://www.example.gov/topic1" /&gt;</code></p>

    <p>By using a canonical link, shown above, you tell the crawler this is the real URL for the page despite parameters present in the URL when the page is opened. In the example above, even if a crawler opened the page with a URL like <code>https://example.gov/topic1?sortby=desc</code>, only <code>https://www.example.gov/topic1</code> will be captured by the search engine.</p>

    <p>Another important use-case for canonical links is the dynamic list. If the example above is a dynamic list of pages about Topic 1, it’s likely there will be pagination at the bottom of the page. This pagination dynamically separates items into distinct pages and generates urls like: <code>https://example.gov/topic1?page=3</code>. As new items are added to or removed from the list, there’s no guarantee that existing items will remain on a particular page. This behavior may frustrate users when a particular page no longer contains the item they want.</p>

    <p>Use a canonical link to limit the search engine to indexing only the first page of the list, which the user can then sort or move through as they choose. The individual items on the list are indexed separately and included in search results.</p>

    <p><br />
<a id="robots"></a></p>
    <h2 id="robots-meta-tags">Robots meta tags</h2>
    <h3 id="exclude-particular-pages-from-indexing-or-exclude-their-links-from-being-followed">Exclude particular pages from indexing, or exclude their links from being followed</h3>

    <p>There are individual pages on your websites that do not make good search results. This could be archived event pages, list views such as Recent Blog Posts, etc. Blocking individual pages on the <a href="/blog/robotstxt.html">robots.txt file</a> will be difficult if you don’t have easy access to edit the file Even if edits are easy, it could quickly lead to an unmanageably long <code>robots.txt</code>.</p>

    <p>It’s also important to note that search engines will pay attention to <code>Disallow</code> directives in <code>robots.txt</code> when crawling, but may not when accessing your URLs from other sources, like links from other sites or your sitemap. <strong>Search.gov will rely on robots meta tags when working off your sitemap to know what content you want searchable, and what you don’t want searchable.</strong></p>

    <p>To achieve best results for blocking indexing of particular pages, you’ll want to employ meta robots tags in the <code>&lt;head&gt;</code> of the pages you want to exclude from the search index.</p>

    <p>This example says not to index the page, but allows following the links on the page:</p>

    <p><code>&lt;meta name="robots" content="noindex" /&gt;</code></p>

    <p>This example says to index the page, but not follow any of the links on the page:</p>

    <p><code>&lt;meta name="robots" content="nofollow" /&gt;</code></p>

    <p>This example tells bots not to index the page, and not to follow any of the links on the page:</p>

    <p><code>&lt;meta name="robots" content="noindex, nofollow" /&gt;</code></p>

    <p>You can also add an X-Robots-Tag to you HTTP header response to control indexing for a given page. This requires deeper access to servers than our customers usually have themselves, so if you are interested in learning more, you can do so <a href="https://developers.google.com/search/reference/robots_meta_tag">here</a>  <i class="icon-external-link"><span>(External link)</span></i>.</p>

    <p>If you have content that should be indexed when it’s fresh, but needs to be removed from the index once it’s outdated, you’ll want to take a few actions:</p>

    <ul>
  <li>Once the page’s window of relevance is over, add a <code>&lt;meta name="robots" content="noindex" /&gt;</code> tag to the <code>&lt;head&gt;</code> of the page.</li>
  <li>Make sure the modified_time on the page is updated.</li>
  <li>Leave the item in the <a href="/blog/sitemaps.html">sitemap</a>, so that search engines will see the page was updated, revisit it, and see that the item should be removed from the index.</li>
</ul>

    <p><br />
<a id="sample"></a></p>
    <h2 id="sample-code-structure">Sample code structure</h2>

    <ul>
  <li><a href="#list1">Dynamic list 1: Topic landing page</a></li>
  <li><a href="#list2">Dynamic list 2: Posts tagged XYZ page</a></li>
  <li><a href="#past-event">Event from last month</a></li>
</ul>

    <p><a id="list1"></a></p>
    <h3 id="dynamic-list-1-topic-landing-page">Dynamic list 1: Topic landing page</h3>

    <p>The following code sample is for a dynamically generated list of pages on your site, where you want the landing page for the list to appear in search results.</p>

    <pre><code>&lt;head&gt;
&lt;title&gt;Unique title of the page&lt;/title&gt;
&lt;meta name="description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time." /&gt;
&lt;meta property="og:title" content="Unique title of the page" /&gt;
&lt;meta property="og:description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time. This could be the same or slightly different than the regular meta description." /&gt;
&lt;meta property=”article:published_time” content=”2018-09-28” /&gt;
&lt;meta property=”article:modified_time” content=”2018-09-28” /&gt;
&lt;link rel="canonical" href="https://www.example.gov/topic1" /&gt;
&lt;/head&gt;

&lt;body&gt;
Redundant header code and navigation elements, sidebars, etc.
&lt;main&gt;
&lt;h1&gt;Unique title of the page&lt;/h1&gt;
&lt;p&gt;This is the introductory text of the page. It tells people what they’ll find here, why the topic is important, etc. This text is within the main element, and so it will be used to retrieve this page in searches.
&lt;/main&gt;
Dynamically generated list of relevant pages
Pagination
Redundant footer code
Various scripts, etc.
&lt;/body&gt;
</code></pre>

    <p><a id="list2"></a></p>
    <h3 id="dynamic-list-2-posts-tagged-xyz">Dynamic list 2: Posts tagged XYZ</h3>

    <p>The following code sample is for a dynamically generated list of pages on your site, where you do not want the list to appear in search results. In the case of pages tagged with a particular term, the pages themselves would be good search results, but the list of them would be just another click between the user and the content.</p>

    <p>Note: the description tags are still present in case someone links to this page in another system and that system wants to display a summary with the link.</p>

    <pre><code>&lt;head&gt;
&lt;title&gt;Unique title of the page&lt;/title&gt;
&lt;meta name="robots" content="noindex" /&gt;
&lt;meta name="description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time. Recommended max characters is 175." /&gt;
&lt;meta property="og:title" content="Unique title of the page" /&gt;
&lt;meta property="og:description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time. Recommended max characters is 175. This could be the same or slightly different than the regular meta description." /&gt;
&lt;meta property=”article:published_time” content=”2018-09-28” /&gt;
&lt;meta property=”article:modified_time” content=”2018-09-28” /&gt;
&lt;link rel="canonical" href="https://www.example.gov/posts-tagged-xyz" /&gt;
&lt;/head&gt;

&lt;body&gt;
Redundant header code and navigation elements, sidebars, etc.
&lt;h1&gt;Unique title of the page&lt;/h1&gt;
Dynamically generated list of relevant pages
Pagination
Redundant footer code
Various scripts, etc.
&lt;/body&gt;
</code></pre>

    <p><a id="past-event"></a></p>
    <h3 id="event-from-last-month">Event from last month</h3>

    <p>In the following example, an event page was published in June, and then updated the day after the event occurred. This update adds the <code>meta robots</code> tag, which declares the page should not be indexed, and links from the page should not be followed in future crawls. Again, the meta descriptions are retained in case of linking from other systems.</p>

    <pre><code>&lt;head&gt;
&lt;title&gt;Unique title of the page&lt;/title&gt;
&lt;meta name="robots" content="noindex, nofollow" /&gt;
&lt;meta name="description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time. Recommended max characters is 175." /&gt;
&lt;meta property="og:title" content="Unique title of the page" /&gt;
&lt;meta property="og:description" content="Some multi-sentence description of various things a person will find on this page. This is a great place to use different terms for the same thing, which is hopefully both plain language and keyword stuffing at the same time. Recommended max characters is 175. This could be the same or slightly different than the regular meta description." /&gt;
&lt;meta property=”article:published_time” content=”2018-06-04” /&gt;
&lt;meta property=”article:modified_time” content=”2018-08-13” /&gt;
&lt;link rel="canonical" href="https://www.example.gov/events/august-12-title-of-event" /&gt;
&lt;/head&gt;

&lt;body&gt;
Redundant header code and navigation elements, sidebars, etc.
&lt;main&gt;
&lt;h1&gt;Unique title of the page&lt;/h1&gt;
&lt;p&gt;This is the introductory text of the page. It tells people what they’ll find here, why the topic is important, etc. This text is within the main element, and so it will be used to retrieve this page in searches.
Specifics about the event.
&lt;/main&gt;
Redundant footer code
Various scripts, etc.
&lt;/body&gt;
</code></pre>

    <h2 id="resources">Resources</h2>

    <ul>
  <li><a href="https://www.w3schools.com/tags/tag_main.asp">HTML &lt;main&gt; Tag</a>  <i class="icon-external-link"><span>(External link)</span></i> - accessed October 10, 2018.</li>
  <li><a href="https://developers.google.com/search/reference/robots_meta_tag">Robots meta tag and X-Robots-Tag HTTP header specifications
</a>  <i class="icon-external-link"><span>(External link)</span></i> - accessed October 10, 2018.</li>
  <li><a href="https://yoast.com/rel-canonical/">rel=canonical: the ultimate guide
</a>  <i class="icon-external-link"><span>(External link)</span></i> - accessed October 10, 2018.</li>
  <li><a href="https://support.google.com/webmasters/answer/139066?hl=en">Consolidate duplicate URLs: Define a canonical page for similar or duplicate pages</a>  <i class="icon-external-link"><span>(External link)</span></i> - accessed October 10, 2018.</li>
</ul>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/indexing"&gt;&lt;span class="label label-info"&gt;indexing&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/seo"&gt;&lt;span class="label label-info"&gt;seo&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/blog/how-search-engines-index-content-better-discoverability.html"&gt;
    &lt;time datetime="2018-10-11"&gt;October 11, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/manual/cname.html"&gt;How to Mask Your Domain&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;We offer DNS masking, which allows you to show searchers search.YOURAGENCY.gov (instead of search.USA.gov). Follow these steps to mask your domain. Please note that due to limitations in the size of our SSL certificate, we are only able to offer top level domain masking: i.e., &lt;code&gt;search.youragency.gov&lt;/code&gt; but not &lt;code&gt;search.subagency.youragency.gov&lt;/code&gt;.&lt;/p&gt;
</code></pre>

    <ol>
  <li>
    <p>Create a <code>search</code> subdomain for your domain. If <code>search</code> is already in use in your environment, you could use <code>find</code> or <code>findit</code> as your subdomain.</p>
  </li>
  <li>
    <p>Create a CNAME in your external DNS records for <code>search.youragency.gov</code>. Point it to <code>yoursitehandle.sites.infr.search.usa.gov</code>. Your site handle is listed on the <a href="/manual/settings.html">settings page</a> in the Search Admin Center.</p>

    <p>For example: if your site handle is <code>abc</code>, the DNS record would look like this:</p>

    <pre><code> search.youragency.gov   CNAME  abc.sites.infr.search.usa.gov
</code></pre>

    <p>NOTE: if your site handle contains a <code>.</code>, please replace it with a <code>-</code> in your DNS record,  e.g., for site handle <code>abc.gov.search</code> the DNS record would look like this:</p>

    <pre><code> search.youragency.gov   CNAME  abc-gov-search.sites.infr.search.usa.gov
</code></pre>
  </li>
  <li>
    <p>After your DNS record has been added, <a href="mailto:search@support.digitalgov.gov">email us</a> to request to be added to our SSL certificate. If your CNAME is not on our SSL certificate, browser security warnings will appear when your search results page attemps to load over <code>HTTPS</code>. It generally takes a few days for these requests to get through our queue.<br /><br />Your domain mask will work as soon as these two steps are complete.</p>
  </li>
  <li>
    <p>When your DNS record is in place and you have received confirmation that your domain mask has been added to our SSL certificate, change your search box’s <a href="/manual/code.html">form code</a> action from <code>search.usa.gov/search</code> to <code>search.youragency.gov/search</code>.</p>
  </li>
</ol>

    <hr />

    <p><strong><em>Troubleshooting tip:</em></strong> Many agencies have both internal and external DNS. Be
sure to update your <em>external</em> DNS records (step 1) before changing your form code (step 2).</p>

    <p><strong><em>Did you know?</em></strong> Any search site within your domain may use the same domain mask and CNAME record, even if the CNAME is not associated with that particular site’s handle. To implement an existing mask for a search box, just do Step 2, above.</p>

    <p><strong><em>Did you know?</em></strong> Once the CNAME is set up, if visitors to your site happen to truncate the URL in the browser bar to http://search.youragency.gov (without any parameters), they’re automatically redirected to your agency’s homepage at http://www.youragency.gov.</p>

    <p><strong><em>Did you know?</em></strong> Most of our customers use a <code>search.youragency.gov</code> mask (such as search.nih.gov). If the <code>search</code> subdomain is already used by another application, you can use <code>find</code> or <code>findit</code>, such as <code>find.irs.gov</code> or <code>findit.state.gov</code>. We no longer support other subdomain patterns.</p>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/help-manual"&gt;&lt;span class="label label-info"&gt;help-manual&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/activate-search"&gt;&lt;span class="label label-info"&gt;activate-search&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/cname"&gt;&lt;span class="label label-info"&gt;cname&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/manual/cname.html"&gt;
    &lt;time datetime="2018-09-21"&gt;September 21, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/releases/august-2018.html"&gt;August 2018 Release Notes&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;h2 id="highlights"&gt;Highlights&lt;/h2&gt;
</code></pre>
    <ul>
  <li>We began work on leveraging click data in our relevancy scoring. This will allow us to use the relative popularity of pages as a ranking signal.</li>
</ul>

    <h2 id="chores">Chores</h2>
    <ul>
  <li>We now record the domain of a URL that has been clicked in addition to recording the full click. This way we can compare the click volume of URLs within a given domain.</li>
  <li>We resolved security vulnerabilities in grape &amp; sprockets</li>
  <li>Configure rspec to run specs in random order</li>
</ul>

    <h2 id="bug-fixes">Bug Fixes</h2>
    <ul>
  <li>None</li>
</ul>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/release-notes"&gt;&lt;span class="label label-info"&gt;release-notes&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  &lt;/br&gt;&lt;span&gt;Page last reviewed or updated:&lt;/span&gt;
  
  
  
  &lt;a href="/releases/august-2018.html"&gt;
    &lt;time datetime="2018-09-21"&gt;September 21, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/manual/users.html"&gt;Managing Your Site's Users&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;&lt;a href="/index.html"&gt;Search.gov Home&lt;/a&gt; &amp;gt; &lt;a href="https://search.usa.gov/sites/"&gt;Admin Center&lt;/a&gt; &amp;gt; YourSite &amp;gt; Dashboard &amp;gt; Manage Users&lt;/p&gt;
</code></pre>

    <p>After you’ve <a href="https://search.usa.gov/sites/">logged in</a> and <a href="/manual/add-site.html">added a site</a> with your official government email, you can add your coworkers to your site.</p>

    <p>You can add anyone you’d like to your site—with or without a .gov or .mil email address. Email addresses outside the .gov or .mil domains must be associated with a business. Personal emails, such as @gmail.com or @yahoo.com, are not allowed.</p>

    <p><img src="https://d3qcdigd1fhos0.cloudfront.net/blog/img/user.png" alt="Add a user" height="95%" width="95%" /></p>

    <p>We use <a href="/manual/color-codes.html">color coding</a> to indicate each user’s status.</p>

    <table>
  <thead>
    <tr>
      <th style="text-align: left">Color</th>
      <th style="text-align: left">Status</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">No color   </td>
      <td style="text-align: left">Approved         </td>
    </tr>
    <tr>
      <td style="text-align: left">Yellow</td>
      <td style="text-align: left">Pending email verification: user must verify their email address via the introductory email they received from our system</td>
    </tr>
    <tr>
      <td style="text-align: left">Yellow</td>
      <td style="text-align: left">Pending approval: requires manual approval by the Search.gov team</td>
    </tr>
    <tr>
      <td style="text-align: left">Red</td>
      <td style="text-align: left">Not approved: to regain access, the user must be manually re-approved by the Search.gov team</td>
    </tr>
  </tbody>
</table>

    <hr />

    <p><strong><em>Did you know?</em></strong> We recommend adding a generic email account (such as webteam@agency.gov) as a user to ensure ongoing access to your account as individuals come and go.</p>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/help-manual"&gt;&lt;span class="label label-info"&gt;help-manual&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/dashboard"&gt;&lt;span class="label label-info"&gt;dashboard&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/users"&gt;&lt;span class="label label-info"&gt;users&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/manual/users.html"&gt;
    &lt;time datetime="2018-08-10"&gt;August 10, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/releases/june-july-2018.html"&gt;June-July 2018 Release Notes&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;h2 id="highlights"&gt;Highlights&lt;/h2&gt;
</code></pre>
    <ul>
  <li>We added support for XML sitemaps that are located in non-standard locations within a domain.</li>
  <li>We added sort_by support to our Results API</li>
</ul>

    <h2 id="chores">Chores</h2>
    <ul>
  <li>We finished migrating to CircleCI for our continuous integration monitoring.</li>
  <li>We improved our internal tracking of queries to the Bing API.</li>
  <li>We improved how we handle indexing domains that time out.</li>
  <li>We began indexing the last-modified date of a page, if provided</li>
  <li>Our SitemapIndexer now processes one sitemap at a time, and we created an automated queue for indexing jobs and url fetching.</li>
  <li>We improved the management of Searchgov domain states. Now each Searchgov domain has an “indexing activity”. States might include: indexing sitemaps, fetching new URLs (such as after bulk import), and crawling.</li>
  <li>We now follow client-side redirects.</li>
  <li>We improved our ability to avoid certain crawler traps.</li>
  <li>We now index documents up to 15 MB in size. The previous limit was 10 MB.</li>
  <li>We finalized our compliance with BOD 18-01.</li>
  <li>We cleaned up how we handle temp files during indexing.</li>
  <li>We tidied up our internal errors on indexing jobs, as well as our test suite.</li>
</ul>

    <h2 id="bug-fixes">Bug Fixes</h2>
    <ul>
  <li>We fixed a bug that was not showing diacritics properly in non-English searches.</li>
</ul>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/release-notes"&gt;&lt;span class="label label-info"&gt;release-notes&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  &lt;/br&gt;&lt;span&gt;Page last reviewed or updated:&lt;/span&gt;
  
  
  
  &lt;a href="/releases/june-july-2018.html"&gt;
    &lt;time datetime="2018-08-10"&gt;August 10, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/index.html"&gt;Search.gov&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;article class="article feature" style="padding:0 30px; margin-top: 10px;"&gt;
</code></pre>
    <div class="banner" style="text-center center-block">
      <pre><code>&lt;p&gt;&lt;a href="/"&gt;
&lt;img class="img-responsive center-block" src="/img/searchdotgovlogo.png" alt="Search.gov logo" /&gt;   &lt;/a&gt;&lt;/p&gt;
</code></pre>
    </div>

    <div style="text-align: center;">
      <pre><code>&lt;h1&gt;Powering over 1,900 search boxes on Federal websites.&lt;/h1&gt;
</code></pre>
    </div>

    <blockquote>
      <pre><code>&lt;p&gt;“It would be impossible to match the value of GSA’s Search service by procuring, building, and configuring a custom solution ourselves. With the combination of a very feature-rich search service and knowledgeable staff, this is by far the best search tool ever.” &lt;small&gt;&lt;cite&gt;Department of Homeland Security&lt;/cite&gt;&lt;/small&gt;&lt;/p&gt;
</code></pre>
    </blockquote>

    <div class="signup-wrapper">
      <pre><code>&lt;p&gt;&lt;a href="http://search.usa.gov/signup" class="btn btn-primary btn-large"&gt;Federal agencies, try our service today!&lt;/a&gt;&lt;/p&gt;
</code></pre>
    </div>

    <h2 id="new-to-our-service">New to our service?</h2>

    <p>Watch our <a href="https://www.youtube.com/watch?v=p-y9T23ziEg">Getting Started video</a> (4 mins) <i class="icon-external-link"><span>(External link)</span></i>, or <a href="/manual/training.html">view a recording</a> of Intro to Search.gov, a 1 hour overview of our system.  Our <a href="/manual/index.html">Help Manual</a> is a section by section list of everything you’ll see inside the Search Admin Center (the administrative dashboard you see after logging in).</p>

    <p>Getting ready to launch? Before you go live with our service, we’ll want to talk to you about your website and options for indexing your content. <a href="mailto:search@support.digitalgov.gov">Reach out to us</a> and we can schedule a call.  You can also review our <a href="/blog/go-live.html">go-live checklist</a> for tips and reminders.</p>

    <p>We also hold regular <a href="/manual/training.html">training sessions</a>. Register now for upcoming training, or watch recordings of previous sessions.</p>

    <h2 id="popular-links">Popular Links</h2>

    <ul>
    <li><a href="/blog/sitemaps.html">All about XML Sitemaps</a></li>
    <li><a href="/manual/index.html">Help manual</a></li>
    <li><a href="/blog/redesign.html">Updating your search after a redesign, move to a new CMS, or both</a></li>
    <li><a href="/manual/cname.html">Masking your domain</a></li>
    <li><a href="/developer/index.html">Developer resources</a></li>
    <li><a href="/tagged/release-notes/">Monthly release notes: the latest features, fixes, and focuses of the Search team</a></li>
    <li><a href="/customers.html">Our customers and history</a></li>
  </ul>

    <h2 id="need-help-were-here-to-help">Need Help? We’re Here to Help!</h2>

    <p>Email us at <a href="mailto:search@support.digitalgov.gov">search@support.digitalgov.gov</a>, or give us a call at 202-969-7426.</p>

    <p>If you’re a federal agency in the DC area, we’d be happy to stop by your office for an in-person consultation. <a href="mailto:search@support.digitalgov.gov">Email us</a> to set up a time.</p>
  </article>

  <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/index.html"&gt;
    &lt;time datetime="2018-06-28"&gt;June 28, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  <p>&lt;/article&gt;</p>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/developer/index.html"&gt;Resources for Developers&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;In line with the White House’s &lt;a href="https://www.whitehouse.gov/sites/default/files/omb/egov/digital-government/digital-government.html"&gt;Digital Government Strategy&lt;/a&gt;, we’re making our code and data more open.&lt;/p&gt;
</code></pre>

    <h2 id="apis-for-searchgov-customers">APIs for Search.gov Customers</h2>

    <p>These APIs are available for use on official government websites only. You must be a Search.gov customer. <a href="https://search.usa.gov/sites">Sign in</a> is required.</p>

    <p><strong><a href="/developer/i14y.html">i14y</a></strong>—This API allows you to send content directly from your content management system (CMS) into Search.gov for real-time indexing. Instructions can be found under <a href="https://search.usa.gov/sites/">Admin Center</a> &gt; YourSite &gt; Content &gt; i14y. Request your site be activated for i14y to enable this section.</p>

    <p><strong><a href="/manual/search-results-api.html">Search Results API</a></strong>—This API exposes all relevant results “modules” in a single JSON call, including: web results, best bets, health topics, job openings, recent tweets, recent news, recent videos, <em>Federal Register</em> documents, and related searches. Use it to <strong><em>pull search results</em></strong> from our service to display on your agency’s website or mobile applications. Instructions can be found under <a href="https://search.usa.gov/sites/">Admin Center</a> &gt; YourSite &gt; Activate Search.</p>

    <p><strong><a href="/manual/typeahead-api.html">Type-ahead API</a></strong>—This API exposes the type-ahead suggestions that often appear below your search box as searchers enter their search terms. Instructions can be found under <a href="https://search.usa.gov/sites/">Admin Center</a> &gt; YourSite &gt; Activate Search.</p>

    <h2 id="apis-and-data-feeds-for-the-public">APIs and Data Feeds for the Public</h2>

    <p><strong><a href="jobs.html">Jobs API</a></strong>—Taps into a list of current jobs openings in federal agencies. Jobs are searchable by keyword, location, agency, schedule, or any combination of these.</p>

    <p>Visit <a href="https://www.usa.gov/developer">USA.gov/Developer</a> for a full list of USA.gov’s APIs and data feeds available to the public.</p>

    <h2 id="source-code-public-github-repositories">Source Code (Public Github Repositories)</h2>

    <p><strong><a href="https://github.com/GSA/asis">ASIS (Advanced Social Image Search)</a></strong>—The source code that runs our image search. ASIS indexes images from Flickr, Instagram, and media RSS to provide a combined search API.</p>

    <p><strong><a href="https://github.com/GSA/i14y">i14y</a></strong>—The source code that runs our search engine for agencies’ published content. i14y indexes agencies’ published content in real time, for search through our regular search channels.</p>

    <p><strong><a href="https://github.com/GSA/jobs_api">Jobs</a></strong>—The source code that runs our jobs search and <a href="jobs.html">Jobs API</a>. Indexes current jobs openings in federal agencies.</p>

    <p><strong><a href="https://github.com/GSA/govt-urls">Non-.gov URLs</a></strong>—The source code that runs our non-.gov URLs API. Indexes all government URLs that don’t end in .gov or .mil.</p>

    <p><strong><a href="https://github.com/GSA/punchcard">Punchcard</a></strong>—The repository of synonyms, protected words, stop words, localizations, and other vocabularies that we use to improve the precision, recall, and usability of search results.</p>

    <p><strong><a href="https://github.com/gsa/search.digitalgov.gov">search.digitalgov.gov</a></strong>—Pages and layout for our website, <a href="https://search.gov">https://search.gov</a>.</p>

    <p><strong><a href="https://github.com/GSA/sitelink_generator">Site Links</a></strong>—The source code that “decorates” organic web results to provide additional, value-added links to help searchers find what they’re looking for. Currently provides one-click links to EDGAR filings for relevant SEC.gov results. Also published as a Ruby gem at <a href="https://rubygems.org/gems/sitelink_generator">https://rubygems.org/gems/sitelink_generator</a>.</p>

    <p><strong><a href="https://github.com/GSA/activerecord-validate_unique_child_attribute">Unique Child Attribute</a></strong>—activerecord-validate_unique_child_attribute is an ActiveRecord extension to enforce uniqueness validations when accepting nested attributes. Works around <a href="https://github.com/rails/rails/issues/4568">Rails issue #4568</a>.</p>

    <h2 id="cms-modules-and-plugins">CMS Modules and Plugins</h2>

    <p>These modules and plugins were developed by Search.gov customers, not us, but we’re linking to them here so you have easy access to them. Use their respective platforms to connect with their developers and submit issues.</p>

    <p><strong><a href="https://www.drupal.org/project/usasearch">Drupal Module</a></strong>—Allows you to connect your Drupal website to your Search.gov search configuration. The module also supports realtime indexing via Search.gov’s i14y content indexing API. Check out our <a href="/manual/drupal.html">help docs here</a>.</p>

    <p><strong><a href="https://github.com/GSA/sites-digitalgov-search">WordPress Plugin</a></strong>—Starter code - contributions welcome! This plugin allows you to override the default WordPress search and connect your WordPress-powered website to your Search.gov search configuration.</p>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/api"&gt;&lt;span class="label label-info"&gt;api&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/open"&gt;&lt;span class="label label-info"&gt;open&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/developer/index.html"&gt;
    &lt;time datetime="2018-06-27"&gt;June 27, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

  <article class="article">

    <pre><code>&lt;h1&gt;
  &lt;a href="/manual/training.html"&gt;Search.gov Training&lt;/a&gt;
&lt;/h1&gt;


&lt;div class='post-content'&gt;
  &lt;p&gt;&lt;a href="https://www.digital.gov/events/"&gt;DigitalGov Events Calendar&lt;/a&gt;&lt;/p&gt;
</code></pre>

    <h2 id="upcoming-sessions">Upcoming Sessions</h2>

    <ul>
  <li>We hold our Search.gov Intro session a couple times a year.</li>
</ul>

    <p>Have an idea about another topic you’d like us to develop training for? <a href="mailto:search@support.digitalgov.gov">Let us know!</a></p>

    <h2 id="previous-sessions">Previous Sessions</h2>

    <p>Can’t view our YouTube vidoes? When available, a downloadable .mp4 file can be found below each embedded video on this page.</p>

    <h3 id="how-search-engines-index-your-websites">How Search Engines Index Your Websites</h3>
    <p>May 2018 | 48 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/THhe3Z7XSxg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

    <p><em>Resources:</em>
<br /><a href="/files/HowSearchEnginesIndexYourWebsite.pdf">Presentation Slides &amp; Notes</a> (PDF)
<br /><a href="https://d3qcdigd1fhos0.cloudfront.net/media/howsearchenginesindex.mp4">How Search Engines Index Your Websites .mp4</a></p>

    <h3 id="intro-to-searchgov">Intro to Search.gov</h3>
    <p>May 2018 | 60 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/W9gFgy4Jx6k?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

    <p>Download not available at this time.
<br /><em>Note:</em> As new Intro sessions are held, recordings of previous sessions will be taken down.</p>

    <h3 id="structuring-your-site-for-better-seo">Structuring Your Site for Better SEO</h3>
    <p>March 2017 | 59 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/2t5JM5slNSA" frameborder="0" allowfullscreen=""></iframe>

    <p><em>Resources:</em> 
<br /><a href="/files/Structuring Your Site Content for Better SEO Slides.pdf">Presentation Slides</a> (PDF)
<br /><a href="/files/Article Links - Structuring Your Site for Better SEO Webinar.pdf">List of SEO Articles and Resources</a> (PDF)
<br /><a href="https://d3qcdigd1fhos0.cloudfront.net/media/Structuring+Your+Site+for+Better+SEO_051117.mp4">Structuring Your Site .mp4</a></p>

    <h3 id="all-about-analytics-search">All About Analytics: Search</h3>
    <p>June 2016 | 57 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/xL6ipNKPW_Y" frameborder="0" allowfullscreen=""></iframe>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/allaboutanalytics.mp4">All About Analytics .mp4</a></p>

    <h3 id="search-doctor-preventive-care-for-your-search-results">Search Doctor: Preventive Care for Your Search Results</h3>
    <p>April 2016 | 48 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/Wr767ENce_4" frameborder="0" allowfullscreen=""></iframe>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/searchdoctor.mp4">Search Doctor .mp4</a></p>

    <h3 id="digitalgov-search-for-power-users">DigitalGov Search for Power Users</h3>
    <p>February 2016 | 66 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/P47ccZb6Fzc" frameborder="0" allowfullscreen=""></iframe>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/powerusers.mp4">Power Users .mp4</a></p>

    <h3 id="show-me-the-data-leveraging-analytics-in-digitalgov-search">Show Me the Data: Leveraging Analytics in DigitalGov Search</h3>
    <p>December 2015 | 61 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/zMft4VkYZug" frameborder="0" allowfullscreen=""></iframe>

    <p><em>Resources:</em> 
<br /><a href="/files/Mastering_Your_Search_Data-December_2015.pptx">Mastering Your Search Data</a> (Slide deck) / Michelle Chronister, USAgov
<br /><a href="/files/Sample_FY15_Monthly_Search%20Reports-USA.gov.xlsx">USA.gov FY15 Monthly Search Reports</a> (Excel workbook) / Michelle Chronister, USAgov - Modify to use as a template for your agency.
<br /><a href="https://d3qcdigd1fhos0.cloudfront.net/media/showmethedata.mp4">Show Me the Data .mp4</a></p>

    <h3 id="straight-to-the-top-best-bets-in-digitalgov-search">Straight to the Top: Best Bets in DigitalGov Search</h3>
    <p>February 2015 | 55 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/WzQocKYK0t4" frameborder="0" allowfullscreen=""></iframe>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/bestbets.mp4">Straight to the Top .mp4</a></p>

    <h3 id="mastering-your-search-term-data-a-tool-for-faster-smarter-analysis">Mastering Your Search Term Data: A Tool for Faster, Smarter Analysis</h3>
    <p>June 2014 | 58 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/x2_PhowP-DI" frameborder="0" allowfullscreen=""></iframe>

    <p><em>Note:</em> To build your own tool to analyze your search data, read <a href="https://www.digitalgov.gov/2013/10/24/understanding-your-users-needs-by-analyzing-search-terms/">Understanding Your Users’ Needs By Analyzing Search Terms</a> and explore USA.gov’s magic formulas in this <a href="https://www.digitalgov.gov/files/2013/10/usa.gov-monthly-search-reports-fy13.xlsx">spreadsheet</a> (MS Excel, 371 KB, October 2013)</p>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/masteringyoursearchdata.mp4">Mastering Your Search Term Data .mp4</a></p>

    <h2 id="quick-start-video">Quick Start Video</h2>

    <h3 id="getting-started-with-digitalgov-search">Getting Started with DigitalGov Search</h3>
    <p>May 2015 | 4 mins</p>

    <iframe width="560" height="315" src="https://www.youtube.com/embed/TnlpuudK_WY" frameborder="0" allowfullscreen=""></iframe>

    <p><a href="https://d3qcdigd1fhos0.cloudfront.net/media/gettingstarted.mp4">Getting Started .mp4</a></p>

    <pre><code>&lt;/div&gt;

&lt;div class='tags'&gt;
  
  &lt;a href="/tagged/help-manual"&gt;&lt;span class="label label-info"&gt;help-manual&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/training"&gt;&lt;span class="label label-info"&gt;training&lt;/span&gt;&lt;/a&gt;
  
  &lt;a href="/tagged/videos"&gt;&lt;span class="label label-info"&gt;videos&lt;/span&gt;&lt;/a&gt;
  
&lt;/div&gt;

&lt;div class='time'&gt;
  
  
  
  
  &lt;a href="/manual/training.html"&gt;
    &lt;time datetime="2018-06-20"&gt;June 20, 2018&lt;/time&gt;
  &lt;/a&gt;
&lt;/div&gt;
</code></pre>

  </article>

</div>

<ul class="pager">
  <li class="next">
    <a href="/blog/page2">Older &rarr;</a>
  </li>
</ul>
<!-- end /blog/index.md content -->

    </main>
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p><a href="mailto:search@support.digitalgov.gov">Email us</a> or call us at 202-969-7426</p>
    <p> An Official Website of the U.S. Government <br />
      <a href="https://www.gsa.gov/portal/category/25729">Technology Transformation Service</a>, <a href="https://www.gsa.gov/portal/category/100000">U.S. General Services Administration</a>
    </p>
    <ul class="footer-links list-unstyled list-inline">
      <li><a href="https://www.usa.gov">USA.gov</a></li>
      <li class="muted">&bull;</li>
      <li><a href="/tos.html">Terms of Service</a></li>
      <li class="muted">&bull;</li>
      <li><a href="https://www.digitalgov.gov/about/policies/">Site Policies</a></li>
      <li class="muted">&bull;</li>
      <li><a href="/developer/">Developers</a></li>
    </ul>
  </div>
</footer>

<script type="text/javascript">
  //<![CDATA[
  var usasearch_config = { siteHandle:"usasearch" };

jQuery(document).ready(function() {
  $('.typeahead').typeahead({
      source: function (query, process) {
          return $.get('https://search.usa.gov/sayt?name=usasearch&q=' + query, function (data) {
              return process(data);
          });
      }, minLength: 2
  });
})


  // var script = document.createElement("script");
  // script.type = "text/javascript";
  // script.src = "https://search.usa.gov/javascripts/remote.loader.js";
  // document.getElementsByTagName("head")[0].appendChild(script);

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31302465-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

  //]]>
</script>

<script async type="text/javascript" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=GSA" id="_fed_an_ua_tag"></script>


</body>
</html>
